{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install nvidia-modulus\n",
        "!pip install pyvista\n",
        "!pip install trimesh\n",
        "!pip install torch-geometric\n",
        "!pip install torch-scatter\n",
        "!pip install torch-sparse\n",
        "!pip install torch-cluster\n",
        "!pip install torch-spline-conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yLYqYgFK2v3u"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "@author: Mohamed Elrefaie, mohamed.elrefaie@mit.edu mohamed.elrefaie@tum.de\n",
        "\n",
        "This module is part of the research presented in the paper:\n",
        "\"DrivAerNet++: A Large-Scale Multimodal Car Dataset with Computational Fluid Dynamics Simulations and Deep Learning Benchmarks\".\n",
        "\n",
        "This module is used to define both point-cloud based and graph-based models, including RegDGCNN, PointNet, and several Graph Neural Network (GNN) models\n",
        "for the task of surrogate modeling of the aerodynamic drag.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import numpy as np\n",
        "import trimesh\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, global_max_pool, JumpingKnowledge\n",
        "from torch.nn import Sequential, Linear, ReLU, BatchNorm1d, Dropout\n",
        "from torch_geometric.nn import BatchNorm\n",
        "\n",
        "def knn(x, k):\n",
        "    \"\"\"\n",
        "    Computes the k-nearest neighbors for each point in x.\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): The input tensor of shape (batch_size, num_dims, num_points).\n",
        "        k (int): The number of nearest neighbors to find.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Indices of the k-nearest neighbors for each point, shape (batch_size, num_points, k).\n",
        "    \"\"\"\n",
        "    # Calculate pairwise distance, shape (batch_size, num_points, num_points)\n",
        "    inner = -2 * torch.matmul(x.transpose(2, 1), x)\n",
        "    xx = torch.sum(x ** 2, dim=1, keepdim=True)\n",
        "    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
        "\n",
        "    # Retrieve the indices of the k nearest neighbors\n",
        "    idx = pairwise_distance.topk(k=k, dim=-1)[1]\n",
        "    return idx\n",
        "\n",
        "\n",
        "def get_graph_feature(x, k=20, idx=None):\n",
        "    \"\"\"\n",
        "    Constructs local graph features for each point by finding its k-nearest neighbors and\n",
        "    concatenating the relative position vectors.\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): The input tensor of shape (batch_size, num_dims, num_points).\n",
        "        k (int): The number of neighbors to consider for graph construction.\n",
        "        idx (torch.Tensor, optional): Precomputed k-nearest neighbor indices.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The constructed graph features of shape (batch_size, 2*num_dims, num_points, k).\n",
        "    \"\"\"\n",
        "    batch_size = x.size(0)\n",
        "    num_points = x.size(2)\n",
        "    x = x.view(batch_size, -1, num_points)\n",
        "\n",
        "    # Compute k-nearest neighbors if not provided\n",
        "    if idx is None:\n",
        "        idx = knn(x, k=k)\n",
        "\n",
        "    # Prepare indices for gathering\n",
        "    device = x.device\n",
        "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1) * num_points\n",
        "    idx = idx + idx_base\n",
        "    idx = idx.view(-1)\n",
        "\n",
        "    _, num_dims, _ = x.size()\n",
        "    x = x.transpose(2, 1).contiguous()\n",
        "\n",
        "    # Gather neighbors for each point to construct local regions\n",
        "    feature = x.view(batch_size * num_points, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_points, k, num_dims)\n",
        "\n",
        "    # Expand x to match the dimensions for broadcasting subtraction\n",
        "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
        "\n",
        "    # Concatenate the original point features with the relative positions to form the graph features\n",
        "    feature = torch.cat((feature - x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "    return feature\n",
        "\n",
        "\n",
        "class RegDGCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Deep Graph Convolutional Neural Network for Regression Tasks (RegDGCNN) for processing 3D point cloud data.\n",
        "\n",
        "    This network architecture extracts hierarchical features from point clouds using graph-based convolutions,\n",
        "    enabling effective learning of spatial structures.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, args, output_channels=1):\n",
        "        \"\"\"\n",
        "        Initializes the RegDGCNN model with specified configurations.\n",
        "\n",
        "        Args:\n",
        "            args (dict): Configuration parameters including 'k' for the number of neighbors, 'emb_dims' for embedding\n",
        "            dimensions, and 'dropout' rate.\n",
        "            output_channels (int): Number of output channels (e.g., for drag prediction, this is 1).\n",
        "        \"\"\"\n",
        "        super(RegDGCNN, self).__init__()\n",
        "        self.args = args\n",
        "        self.k = args['k']  # Number of nearest neighbors\n",
        "\n",
        "        # Batch normalization layers to stabilize and accelerate training\n",
        "        self.bn1 = nn.BatchNorm2d(256)\n",
        "        self.bn2 = nn.BatchNorm2d(512)\n",
        "        self.bn3 = nn.BatchNorm2d(512)\n",
        "        self.bn4 = nn.BatchNorm2d(1024)\n",
        "        self.bn5 = nn.BatchNorm1d(args['emb_dims'])\n",
        "\n",
        "        # EdgeConv layers: Convolutional layers leveraging local neighborhood information\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(6, 256, kernel_size=1, bias=False),\n",
        "                                   self.bn1,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(256 * 2, 512, kernel_size=1, bias=False),\n",
        "                                   self.bn2,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(512 * 2, 512, kernel_size=1, bias=False),\n",
        "                                   self.bn3,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(512 * 2, 1024, kernel_size=1, bias=False),\n",
        "                                   self.bn4,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv5 = nn.Sequential(nn.Conv1d(2304, args['emb_dims'], kernel_size=1, bias=False),\n",
        "                                   self.bn5,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "\n",
        "        # Fully connected layers to interpret the extracted features and make predictions\n",
        "        self.linear1 = nn.Linear(args['emb_dims']*2, 128, bias=False)\n",
        "        self.bn6 = nn.BatchNorm1d(128)\n",
        "        self.dp1 = nn.Dropout(p=args['dropout'])\n",
        "\n",
        "        self.linear2 = nn.Linear(128, 64)\n",
        "        self.bn7 = nn.BatchNorm1d(64)\n",
        "        self.dp2 = nn.Dropout(p=args['dropout'])\n",
        "\n",
        "        self.linear3 = nn.Linear(64, 32)\n",
        "        self.bn8 = nn.BatchNorm1d(32)\n",
        "        self.dp3 = nn.Dropout(p=args['dropout'])\n",
        "\n",
        "        self.linear4 = nn.Linear(32, 16)\n",
        "        self.bn9 = nn.BatchNorm1d(16)\n",
        "        self.dp4 = nn.Dropout(p=args['dropout'])\n",
        "\n",
        "        self.linear5 = nn.Linear(16, output_channels)  # The final output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model to process input data and predict outputs.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor representing a batch of point clouds.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Model predictions for the input batch.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Extract graph features and apply EdgeConv blocks\n",
        "        x = get_graph_feature(x, k=self.k)  # (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)\n",
        "        x = self.conv1(x)  # (batch_size, 3*2, num_points, k) -> (batch_size, 256, num_points, k)\n",
        "\n",
        "        # Global max pooling\n",
        "        x1 = x.max(dim=-1, keepdim=False)[0]  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n",
        "\n",
        "        # Repeat the process for subsequent EdgeConv blocks\n",
        "        x = get_graph_feature(x1, k=self.k)   # (batch_size, 256, num_points) -> (batch_size, 256*2, num_points, k)\n",
        "        x = self.conv2(x)                     # (batch_size, 256*2, num_points, k) -> (batch_size, 512, num_points, k)\n",
        "        x2 = x.max(dim=-1, keepdim=False)[0]  # (batch_size, 512, num_points, k) -> (batch_size, 512, num_points)\n",
        "\n",
        "        x = get_graph_feature(x2, k=self.k)   # (batch_size, 512, num_points) -> (batch_size, 512*2, num_points, k)\n",
        "        x = self.conv3(x)                     # (batch_size, 512*2, num_points, k) -> (batch_size, 512, num_points, k)\n",
        "        x3 = x.max(dim=-1, keepdim=False)[0]  # (batch_size, 512, num_points, k) -> (batch_size, 512, num_points)\n",
        "\n",
        "        x = get_graph_feature(x3, k=self.k)   # (batch_size, 512, num_points) -> (batch_size, 512*2, num_points, k)\n",
        "        x = self.conv4(x)                     # (batch_size, 512*2, num_points, k) -> (batch_size, 1024, num_points, k)\n",
        "        x4 = x.max(dim=-1, keepdim=False)[0]  # (batch_size, 1024, num_points, k) -> (batch_size, 1024, num_points)\n",
        "\n",
        "        # Concatenate features from all EdgeConv blocks\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)  # (batch_size, 256+512+512+1024, num_points)\n",
        "\n",
        "        # Apply the final convolutional block\n",
        "        x = self.conv5(x)  # (batch_size, 256+512+512+1024, num_points) -> (batch_size, emb_dims, num_points)\n",
        "        # Combine global max and average pooling features\n",
        "        # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims)\n",
        "        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n",
        "        # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims)\n",
        "        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)\n",
        "        x = torch.cat((x1, x2), 1)   # (batch_size, emb_dims*2)\n",
        "\n",
        "        # Process features through fully connected layers with dropout and batch normalization\n",
        "        x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2)  # (batch_size, emb_dims*2) -> (batch_size, 128)\n",
        "        x = self.dp1(x)\n",
        "        x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2)  # (batch_size, 128) -> (batch_size, 64)\n",
        "        x = self.dp2(x)\n",
        "        x = F.leaky_relu(self.bn8(self.linear3(x)), negative_slope=0.2)  # (batch_size, 64) -> (batch_size, 32)\n",
        "        x = self.dp3(x)\n",
        "        x = F.leaky_relu(self.bn9(self.linear4(x)), negative_slope=0.2)  # (batch_size, 32) -> (batch_size, 16)\n",
        "        x = self.dp4(x)\n",
        "\n",
        "        # Final linear layer to produce the output\n",
        "        x = self.linear5(x)                                              # (batch_size, 16) -> (batch_size, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class RegPointNet(nn.Module):\n",
        "    \"\"\"\n",
        "    PointNet-based regression model for 3D point cloud data.\n",
        "\n",
        "    Args:\n",
        "        args (dict): Configuration parameters including 'emb_dims' for embedding dimensions and 'dropout' rate.\n",
        "\n",
        "    Methods:\n",
        "        forward(x): Forward pass through the network.\n",
        "    \"\"\"\n",
        "    def __init__(self, args):\n",
        "        \"\"\"\n",
        "        Initialize the RegPointNet model for regression tasks with enhanced complexity,\n",
        "        including additional layers and residual connections.\n",
        "\n",
        "        Parameters:\n",
        "            emb_dims (int): Dimensionality of the embedding space.\n",
        "            dropout (float): Dropout probability.\n",
        "        \"\"\"\n",
        "        super(RegPointNet, self).__init__()\n",
        "        self.args = args\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv1d(3, 512, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv1d(512, 1024, kernel_size=1, bias=False)\n",
        "        self.conv3 = nn.Conv1d(1024, 1024, kernel_size=1, bias=False)\n",
        "        self.conv4 = nn.Conv1d(1024, 1024, kernel_size=1, bias=False)\n",
        "        self.conv5 = nn.Conv1d(1024, 1024, kernel_size=1, bias=False)\n",
        "        self.conv6 = nn.Conv1d(1024, args['emb_dims'], kernel_size=1, bias=False)\n",
        "\n",
        "        # Batch normalization layers\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(1024)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.bn4 = nn.BatchNorm1d(1024)\n",
        "        self.bn5 = nn.BatchNorm1d(1024)\n",
        "        self.bn6 = nn.BatchNorm1d(args['emb_dims'])\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout_conv = nn.Dropout(p=args['dropout'])\n",
        "        self.dropout_linear = nn.Dropout(p=args['dropout'])\n",
        "\n",
        "        # Residual connection layer\n",
        "        self.conv_shortcut = nn.Conv1d(3, args['emb_dims'], kernel_size=1, bias=False)\n",
        "        self.bn_shortcut = nn.BatchNorm1d(args['emb_dims'])\n",
        "\n",
        "        # Linear layers for regression output\n",
        "        self.linear1 = nn.Linear(args['emb_dims'], 512, bias=False)\n",
        "        self.bn7 = nn.BatchNorm1d(512)\n",
        "        self.linear2 = nn.Linear(512, 256, bias=False)\n",
        "        self.bn8 = nn.BatchNorm1d(256)\n",
        "        self.linear3 = nn.Linear(256, 128)  # Output one scalar value\n",
        "        self.bn9 = nn.BatchNorm1d(128)\n",
        "        self.linear4 = nn.Linear(128, 64)  # Output one scalar value\n",
        "        self.bn10 = nn.BatchNorm1d(64)\n",
        "        self.final_linear = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the network.\n",
        "\n",
        "        Parameters:\n",
        "            x (Tensor): Input tensor of shape (batch_size, 3, num_points).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Output tensor of the predicted scalar value.\n",
        "        \"\"\"\n",
        "        shortcut = self.bn_shortcut(self.conv_shortcut(x))\n",
        "\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.dropout_conv(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.dropout_conv(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.dropout_conv(x)\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.dropout_conv(x)\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = self.dropout_conv(x)\n",
        "        x = F.relu(self.bn6(self.conv6(x)))\n",
        "        # Adding the residual connection\n",
        "        x = x + shortcut\n",
        "\n",
        "        x = F.adaptive_max_pool1d(x, 1).squeeze(-1)\n",
        "        x = F.relu(self.bn7(self.linear1(x)))\n",
        "        x = F.relu(self.bn8(self.linear2(x)))\n",
        "        x = F.relu(self.bn9(self.linear3(x)))\n",
        "        x = F.relu(self.bn10(self.linear4(x)))\n",
        "        features = x\n",
        "        x = self.final_linear(x)\n",
        "\n",
        "        #return x, features\n",
        "        return x\n",
        "\n",
        "class DragGNN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Neural Network for predicting drag coefficients using GCNConv layers.\n",
        "\n",
        "    Args:\n",
        "        None\n",
        "\n",
        "    Methods:\n",
        "        forward(data): Forward pass through the network.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(DragGNN, self).__init__()\n",
        "        self.conv1 = GCNConv(3, 512)\n",
        "        self.conv2 = GCNConv(512, 1024)\n",
        "        self.conv3 = GCNConv(1024, 512)\n",
        "        self.fc1 = torch.nn.Linear(512, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, data: Data) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass through the network.\n",
        "\n",
        "        Args:\n",
        "            data (Data): Input graph data containing node features, edge indices, and batch indices.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output predictions for drag coefficients.\n",
        "        \"\"\"\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DragGNN_XL(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Extended Graph Neural Network for predicting drag coefficients using GCNConv layers and BatchNorm layers.\n",
        "\n",
        "    Args:\n",
        "        None\n",
        "\n",
        "    Methods:\n",
        "        forward(data): Forward pass through the network.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(DragGNN_XL, self).__init__()\n",
        "        self.conv1 = GCNConv(3, 64)\n",
        "        self.conv2 = GCNConv(64, 128)\n",
        "        self.conv3 = GCNConv(128, 128)\n",
        "        self.conv4 = GCNConv(128, 256)\n",
        "\n",
        "        self.bn1 = BatchNorm(64)\n",
        "        self.bn2 = BatchNorm(128)\n",
        "        self.bn3 = BatchNorm(128)\n",
        "        self.bn4 = BatchNorm(256)\n",
        "\n",
        "        self.dropout = Dropout(0.4)\n",
        "\n",
        "        self.fc = Sequential(\n",
        "            Linear(256, 128),\n",
        "            ReLU(),\n",
        "            Dropout(0.4),\n",
        "            Linear(128, 64),\n",
        "            ReLU(),\n",
        "            Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data: Data) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass through the network.\n",
        "\n",
        "        Args:\n",
        "            data (Data): Input graph data containing node features, edge indices, and batch indices.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output predictions for drag coefficients.\n",
        "        \"\"\"\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x, edge_index)))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.bn4(self.conv4(x, edge_index)))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EnhancedDragGNN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Enhanced Graph Neural Network for predicting drag coefficients using both GCNConv and GATConv layers,\n",
        "    with Jumping Knowledge for combining features from different layers.\n",
        "\n",
        "    Args:\n",
        "        None\n",
        "\n",
        "    Methods:\n",
        "        forward(data): Forward pass through the network.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(EnhancedDragGNN, self).__init__()\n",
        "        self.gcn1 = GCNConv(3, 64)\n",
        "        self.gat1 = GATConv(64, 64, heads=4, concat=True)\n",
        "\n",
        "        self.bn1 = BatchNorm1d(128)\n",
        "        self.gcn2 = GCNConv(256, 128)\n",
        "        self.gat2 = GATConv(128, 128, heads=2, concat=True)\n",
        "\n",
        "        self.bn2 = BatchNorm1d(256)\n",
        "        self.gcn3 = GCNConv(256, 256)\n",
        "\n",
        "        self.jk = JumpingKnowledge(mode='cat')\n",
        "\n",
        "        self.fc1 = Sequential(\n",
        "            Linear(256 * 3, 128),\n",
        "            ReLU(),\n",
        "            BatchNorm1d(128)\n",
        "        )\n",
        "        self.fc2 = Linear(128, 1)\n",
        "\n",
        "    def forward(self, data: Data) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass through the network.\n",
        "\n",
        "        Args:\n",
        "            data (Data): Input graph data containing node features, edge indices, and batch indices.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output predictions for drag coefficients.\n",
        "        \"\"\"\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        x1 = F.relu(self.gcn1(x, edge_index))\n",
        "        x1 = F.dropout(x1, p=0.2, training=self.training)\n",
        "        x1 = self.gat1(x1, edge_index)\n",
        "\n",
        "        x2 = F.relu(self.bn1(self.gcn2(x1, edge_index)))\n",
        "        x2 = F.dropout(x2, p=0.2, training=self.training)\n",
        "        x2 = self.gat2(x2, edge_index)\n",
        "\n",
        "        x3 = F.relu(self.bn2(self.gcn3(x2, edge_index)))\n",
        "\n",
        "        x = self.jk([x1, x2, x3])\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cEAiHy1L3QIm"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "@author: Mohamed Elrefaie, mohamed.elrefaie@mit.edu mohamed.elrefaie@tum.de\n",
        "\n",
        "This module is part of the research presented in the paper:\n",
        "\"DrivAerNet++: A Large-Scale Multimodal Car Dataset with Computational Fluid Dynamics Simulations and Deep Learning Benchmarks\".\n",
        "\n",
        "The module defines two PyTorch Datasets for loading and transforming 3D car models from the DrivAerNet++ dataset:\n",
        "1. DrivAerNetDataset: Handles point cloud data, allowing loading, transforming, and augmenting 3D car models from STL files or existing point clouds.\n",
        "2. DrivAerNetGNNDataset: Processes the dataset into graph format suitable for Graph Neural Networks (GNNs).\n",
        "\"\"\"\n",
        "import os\n",
        "import logging\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import trimesh\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pyvista as pv\n",
        "import seaborn as sns\n",
        "from typing import Callable, Optional, Tuple, List\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class DataAugmentation:\n",
        "    \"\"\"\n",
        "    Class encapsulating various data augmentation techniques for point clouds.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def translate_pointcloud(pointcloud: torch.Tensor, translation_range: Tuple[float, float] = (2./3., 3./2.)) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Translates the pointcloud by a random factor within a given range.\n",
        "\n",
        "        Args:\n",
        "            pointcloud: The input point cloud as a torch.Tensor.\n",
        "            translation_range: A tuple specifying the range for translation factors.\n",
        "\n",
        "        Returns:\n",
        "            Translated point cloud as a torch.Tensor.\n",
        "        \"\"\"\n",
        "        # Randomly choose translation factors and apply them to the pointcloud\n",
        "        xyz1 = np.random.uniform(low=translation_range[0], high=translation_range[1], size=[3])\n",
        "        xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])\n",
        "        translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')\n",
        "        return torch.tensor(translated_pointcloud, dtype=torch.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def jitter_pointcloud(pointcloud: torch.Tensor, sigma: float = 0.01, clip: float = 0.02) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Adds Gaussian noise to the pointcloud.\n",
        "\n",
        "        Args:\n",
        "            pointcloud: The input point cloud as a torch.Tensor.\n",
        "            sigma: Standard deviation of the Gaussian noise.\n",
        "            clip: Maximum absolute value for noise.\n",
        "\n",
        "        Returns:\n",
        "            Jittered point cloud as a torch.Tensor.\n",
        "        \"\"\"\n",
        "        # Add Gaussian noise and clip to the specified range\n",
        "        N, C = pointcloud.shape\n",
        "        jittered_pointcloud = pointcloud + torch.clamp(sigma * torch.randn(N, C), -clip, clip)\n",
        "        return jittered_pointcloud\n",
        "\n",
        "    @staticmethod\n",
        "    def drop_points(pointcloud: torch.Tensor, drop_rate: float = 0.1) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Randomly removes points from the point cloud based on the drop rate.\n",
        "\n",
        "        Args:\n",
        "            pointcloud: The input point cloud as a torch.Tensor.\n",
        "            drop_rate: The percentage of points to be randomly dropped.\n",
        "\n",
        "        Returns:\n",
        "            The point cloud with points dropped as a torch.Tensor.\n",
        "        \"\"\"\n",
        "        # Calculate the number of points to drop\n",
        "        num_drop = int(drop_rate * pointcloud.size(0))\n",
        "        # Generate random indices for points to drop\n",
        "        drop_indices = np.random.choice(pointcloud.size(0), num_drop, replace=False)\n",
        "        keep_indices = np.setdiff1d(np.arange(pointcloud.size(0)), drop_indices)\n",
        "        dropped_pointcloud = pointcloud[keep_indices, :]\n",
        "        return dropped_pointcloud\n",
        "\n",
        "class DrivAerNetDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset class for the DrivAerNet dataset, handling loading, transforming, and augmenting 3D car models.\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir: str, csv_file: str, num_points: int, transform: Optional[Callable] = None, pointcloud_exist: bool = False):\n",
        "        \"\"\"\n",
        "        Initializes the DrivAerNetDataset instance.\n",
        "\n",
        "        Args:\n",
        "            root_dir: Directory containing the STL files for 3D car models.\n",
        "            csv_file: Path to the CSV file with metadata for the models.\n",
        "            num_points: Fixed number of points to sample from each 3D model.\n",
        "            transform: Optional transform function to apply to each sample.\n",
        "            pointcloud_exist (bool): Whether the point clouds already exist as .pt files.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        try:\n",
        "            self.data_frame = pd.read_csv(csv_file)\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load CSV file: {csv_file}. Error: {e}\")\n",
        "            raise\n",
        "\n",
        "        self.transform = transform\n",
        "        self.num_points = num_points\n",
        "        self.augmentation = DataAugmentation()\n",
        "        self.pointcloud_exist = pointcloud_exist\n",
        "        self.cache = {}\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def min_max_normalize(self, data: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Normalizes the data to the range [0, 1] based on min and max values.\n",
        "        \"\"\"\n",
        "        min_vals, _ = data.min(dim=0, keepdim=True)\n",
        "        max_vals, _ = data.max(dim=0, keepdim=True)\n",
        "        normalized_data = (data - min_vals) / (max_vals - min_vals)\n",
        "        return normalized_data\n",
        "\n",
        "    def z_score_normalize(self, data: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Normalizes the data using z-score normalization (standard score).\n",
        "        \"\"\"\n",
        "        mean_vals = data.mean(dim=0, keepdim=True)\n",
        "        std_vals = data.std(dim=0, keepdim=True)\n",
        "        normalized_data = (data - mean_vals) / std_vals\n",
        "        return normalized_data\n",
        "\n",
        "    def mean_normalize(self, data: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Normalizes the data to the range [-1, 1] based on mean and range.\n",
        "        \"\"\"\n",
        "        mean_vals = data.mean(dim=0, keepdim=True)\n",
        "        min_vals, _ = data.min(dim=0, keepdim=True)\n",
        "        max_vals, _ = data.max(dim=0, keepdim=True)\n",
        "        normalized_data = (data - mean_vals) / (max_vals - min_vals)\n",
        "        return normalized_data\n",
        "    def _sample_or_pad_vertices(self, vertices: torch.Tensor, num_points: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Subsamples or pads the vertices of the model to a fixed number of points.\n",
        "\n",
        "        Args:\n",
        "            vertices: The vertices of the 3D model as a torch.Tensor.\n",
        "            num_points: The desired number of points for the model.\n",
        "\n",
        "        Returns:\n",
        "            The vertices standardized to the specified number of points.\n",
        "        \"\"\"\n",
        "        num_vertices = vertices.size(0)\n",
        "        if num_vertices > num_points:\n",
        "            indices = np.random.choice(num_vertices, num_points, replace=False)\n",
        "            vertices = vertices[indices]\n",
        "        elif num_vertices < num_points:\n",
        "            padding = torch.zeros((num_points - num_vertices, 3), dtype=torch.float32)\n",
        "            vertices = torch.cat((vertices, padding), dim=0)\n",
        "        return vertices\n",
        "\n",
        "    def _load_point_cloud(self, design_id: str) -> Optional[torch.Tensor]:\n",
        "        load_path = os.path.join(self.root_dir, f\"{design_id}.pt\")\n",
        "        if os.path.exists(load_path) and os.path.getsize(load_path) > 0:\n",
        "            try:\n",
        "                return torch.load(load_path)\n",
        "            except (EOFError, RuntimeError) as e:\n",
        "                #logging.error(f\"Failed to load point cloud file {load_path}: {e}\")\n",
        "                return None\n",
        "        else:\n",
        "            #logging.error(f\"Point cloud file {load_path} does not exist or is empty.\")\n",
        "            return None\n",
        "\n",
        "    def __getitem__(self, idx: int, apply_augmentations: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Retrieves a sample and its corresponding label from the dataset, with an option to apply augmentations.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sample to retrieve.\n",
        "            apply_augmentations (bool, optional): Whether to apply data augmentations. Defaults to True.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]: The sample (point cloud) and its label (Cd value).\n",
        "        \"\"\"\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        if idx in self.cache:\n",
        "            return self.cache[idx]\n",
        "        while True:\n",
        "            row = self.data_frame.iloc[idx]\n",
        "            design_id = row['Design']\n",
        "            cd_value = row['Average Cd']\n",
        "\n",
        "            if self.pointcloud_exist:\n",
        "                vertices = self._load_point_cloud(design_id)\n",
        "\n",
        "                if vertices is None:\n",
        "                    #logging.warning(f\"Skipping design {design_id} because point cloud is not found or corrupted.\")\n",
        "                    idx = (idx + 1) % len(self.data_frame)\n",
        "                    continue\n",
        "            else:\n",
        "                geometry_path = os.path.join(self.root_dir, f\"{design_id}.stl\")\n",
        "                try:\n",
        "                    mesh = trimesh.load(geometry_path, force='mesh')\n",
        "                    vertices = torch.tensor(mesh.vertices, dtype=torch.float32)\n",
        "                    vertices = self._sample_or_pad_vertices(vertices, self.num_points)\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Failed to load STL file: {geometry_path}. Error: {e}\")\n",
        "                    raise\n",
        "\n",
        "            if apply_augmentations:\n",
        "                vertices = self.augmentation.translate_pointcloud(vertices.numpy())\n",
        "                vertices = self.augmentation.jitter_pointcloud(vertices)\n",
        "\n",
        "            if self.transform:\n",
        "                vertices = self.transform(vertices)\n",
        "\n",
        "            point_cloud_normalized = self.min_max_normalize(vertices)\n",
        "            cd_value = torch.tensor(float(cd_value), dtype=torch.float32).view(-1)\n",
        "\n",
        "            self.cache[idx] = (point_cloud_normalized, cd_value)\n",
        "            return point_cloud_normalized, cd_value\n",
        "\n",
        "    def split_data(self, train_ratio: float = 0.7, val_ratio: float = 0.15, test_ratio: float = 0.15) -> Tuple[List[int], List[int], List[int]]:\n",
        "        \"\"\"\n",
        "        Splits the dataset into training, validation, and test sets.\n",
        "\n",
        "        Args:\n",
        "            train_ratio: The proportion of the data to be used for training.\n",
        "            val_ratio: The proportion of the data to be used for validation.\n",
        "            test_ratio: The proportion of the data to be used for testing.\n",
        "\n",
        "        Returns:\n",
        "            Indices for the training, validation, and test sets.\n",
        "        \"\"\"\n",
        "        assert train_ratio + val_ratio + test_ratio == 1, \"Ratios must sum to 1\"\n",
        "        num_samples = len(self)\n",
        "        indices = list(range(num_samples))\n",
        "        train_size = int(train_ratio * num_samples)\n",
        "        val_size = int(val_ratio * num_samples)\n",
        "        test_size = num_samples - train_size - val_size\n",
        "        train_indices, val_indices, test_indices = random_split(indices, [train_size, val_size, test_size])\n",
        "        return train_indices, val_indices, test_indices\n",
        "\n",
        "    def visualize_mesh(self, idx):\n",
        "        \"\"\"\n",
        "        Visualize the STL mesh for a specific design from the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the design to visualize in the dataset.\n",
        "\n",
        "        This function loads the mesh from the STL file corresponding to the design ID at the given index,\n",
        "        wraps it using PyVista for visualization, and then sets up a PyVista plotter to display the mesh.\n",
        "        \"\"\"\n",
        "        row = self.data_frame.iloc[idx]\n",
        "        design_id = row['Design']\n",
        "        geometry_path = os.path.join(self.root_dir, f\"{design_id}.stl\")\n",
        "\n",
        "        try:\n",
        "            mesh = trimesh.load(geometry_path, force='mesh')\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load STL file: {geometry_path}. Error: {e}\")\n",
        "            raise\n",
        "\n",
        "        pv_mesh = pv.wrap(mesh)\n",
        "        plotter = pv.Plotter()\n",
        "        plotter.add_mesh(pv_mesh, color='lightgrey', show_edges=True)\n",
        "        plotter.add_axes()\n",
        "\n",
        "        camera_position = [(-11.073024242161921, -5.621499358347753, 5.862225824910342),\n",
        "                           (1.458462064391673, 0.002314306982062475, 0.6792134746589196),\n",
        "                           (0.34000174095454166, 0.10379556639001211, 0.9346792479485448)]\n",
        "        plotter.camera_position = camera_position\n",
        "        plotter.show()\n",
        "\n",
        "    def visualize_mesh_with_node(self, idx):\n",
        "        \"\"\"\n",
        "        Visualizes the mesh for a specific design from the dataset with nodes highlighted.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the design to visualize in the dataset.\n",
        "\n",
        "        This function loads the mesh from the STL file and highlights the nodes (vertices) of the mesh using spheres.\n",
        "        It uses seaborn to obtain visually distinct colors for the mesh and nodes.\n",
        "        \"\"\"\n",
        "        row = self.data_frame.iloc[idx]\n",
        "        design_id = row['Design']\n",
        "        geometry_path = os.path.join(self.root_dir, f\"{design_id}.stl\")\n",
        "\n",
        "        try:\n",
        "            mesh = trimesh.load(geometry_path, force='mesh')\n",
        "            pv_mesh = pv.wrap(mesh)\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load STL file: {geometry_path}. Error: {e}\")\n",
        "            raise\n",
        "\n",
        "        plotter = pv.Plotter()\n",
        "        sns_blue = sns.color_palette(\"colorblind\")[0]\n",
        "\n",
        "        plotter.add_mesh(pv_mesh, color='lightgrey', show_edges=True, edge_color='black')\n",
        "        nodes = pv_mesh.points\n",
        "        plotter.add_points(nodes, color=sns_blue, point_size=5, render_points_as_spheres=True)\n",
        "        plotter.add_axes()\n",
        "        plotter.show()\n",
        "\n",
        "    def visualize_point_cloud(self, idx):\n",
        "        \"\"\"\n",
        "        Visualizes the point cloud for a specific design from the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the design to visualize in the dataset.\n",
        "\n",
        "        This function retrieves the vertices for the specified design, converts them into a point cloud,\n",
        "        and uses the z-coordinate for color mapping. PyVista's Eye-Dome Lighting is enabled for improved depth perception.\n",
        "        \"\"\"\n",
        "        # Retrieve vertices and corresponding CD value for the specified index\n",
        "        vertices, _ = self.__getitem__(idx)\n",
        "        vertices = vertices.numpy()\n",
        "\n",
        "        # Convert vertices to a PyVista PolyData object for visualization\n",
        "        point_cloud = pv.PolyData(vertices)\n",
        "        colors = vertices[:, 2]  # Using the z-coordinate for color mapping\n",
        "        point_cloud[\"colors\"] = colors  # Add the colors to the point cloud\n",
        "\n",
        "        # Set up the PyVista plotter\n",
        "        plotter = pv.Plotter()\n",
        "\n",
        "        # Add the point cloud to the plotter with color mapping based on the z-coordinate\n",
        "        plotter.add_points(point_cloud, scalars=\"colors\", cmap=\"Blues\", point_size=3, render_points_as_spheres=True)\n",
        "\n",
        "        # Enable Eye-Dome Lighting for better depth perception\n",
        "        plotter.enable_eye_dome_lighting()\n",
        "\n",
        "        # Add axes for orientation and display the plotter window\n",
        "        plotter.add_axes()\n",
        "        camera_position = [(-11.073024242161921, -5.621499358347753, 5.862225824910342),\n",
        "                           (1.458462064391673, 0.002314306982062475, 0.6792134746589196),\n",
        "                           (0.34000174095454166, 0.10379556639001211, 0.9346792479485448)]\n",
        "\n",
        "        # Set the camera position\n",
        "        plotter.camera_position = camera_position\n",
        "\n",
        "        plotter.show()\n",
        "\n",
        "    def visualize_augmentations(self, idx):\n",
        "        \"\"\"\n",
        "        Visualizes various augmentations applied to the point cloud of a specific design in the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sample in the dataset to be visualized.\n",
        "\n",
        "        This function retrieves the original point cloud for the specified design and then applies a series of augmentations,\n",
        "        including translation, jittering, and point dropping. Each version of the point cloud (original and augmented) is then\n",
        "        visualized in a 2x2 grid using PyVista to illustrate the effects of these augmentations.\n",
        "        \"\"\"\n",
        "        # Retrieve the original point cloud without applying any augmentations\n",
        "        vertices, _ = self.__getitem__(idx, apply_augmentations=False)\n",
        "        original_pc = pv.PolyData(vertices.numpy())\n",
        "\n",
        "        # Apply translation augmentation to the original point cloud\n",
        "        translated_pc = self.augmentation.translate_pointcloud(vertices.numpy())\n",
        "        # Apply jitter augmentation to the translated point cloud\n",
        "        jittered_pc = self.augmentation.jitter_pointcloud(translated_pc)\n",
        "        # Apply point dropping augmentation to the jittered point cloud\n",
        "        dropped_pc = self.augmentation.drop_points(jittered_pc)\n",
        "\n",
        "        # Initialize a PyVista plotter with a 2x2 grid for displaying the point clouds\n",
        "        plotter = pv.Plotter(shape=(2, 2))\n",
        "\n",
        "        # Display the original point cloud in the top left corner of the grid\n",
        "        plotter.subplot(0, 0)  # Select the first subplot\n",
        "        plotter.add_text(\"Original Point Cloud\", font_size=10)  # Add descriptive text\n",
        "        plotter.add_mesh(original_pc, color='black', point_size=3)  # Add the original point cloud to the plot\n",
        "\n",
        "        # Display the translated point cloud in the top right corner of the grid\n",
        "        plotter.subplot(0, 1)  # Select the second subplot\n",
        "        plotter.add_text(\"Translated Point Cloud\", font_size=10)  # Add descriptive text\n",
        "        plotter.add_mesh(pv.PolyData(translated_pc.numpy()), color='lightblue',\n",
        "                         point_size=3)  # Add the translated point cloud to the plot\n",
        "\n",
        "        # Display the jittered point cloud in the bottom left corner of the grid\n",
        "        plotter.subplot(1, 0)  # Select the third subplot\n",
        "        plotter.add_text(\"Jittered Point Cloud\", font_size=10)  # Add descriptive text\n",
        "        plotter.add_mesh(pv.PolyData(jittered_pc.numpy()), color='lightgreen',\n",
        "                         point_size=3)  # Add the jittered point cloud to the plot\n",
        "\n",
        "        # Display the dropped point cloud in the bottom right corner of the grid\n",
        "        plotter.subplot(1, 1)  # Select the fourth subplot\n",
        "        plotter.add_text(\"Dropped Point Cloud\", font_size=10)  # Add descriptive text\n",
        "        plotter.add_mesh(pv.PolyData(dropped_pc.numpy()), color='salmon',\n",
        "                         point_size=3)  # Add the dropped point cloud to the plot\n",
        "\n",
        "        # Display the plot with all point clouds\n",
        "        plotter.show()\n",
        "\n",
        "class DrivAerNetGNNDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset for loading and processing the DrivAerNet dataset into graph format suitable for GNNs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root_dir: str, csv_file: str, normalize: bool = True):\n",
        "        \"\"\"\n",
        "        Initialize the dataset.\n",
        "\n",
        "        Args:\n",
        "            root_dir (str): Path to the directory containing the STL files.\n",
        "            csv_file (str): Path to the CSV file containing metadata such as aerodynamic coefficients.\n",
        "            normalize (bool): Whether to normalize the node features.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "        self.normalize = normalize\n",
        "        self.cache = {}\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Return the length of the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: Number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def min_max_normalize(self, data: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Normalizes the data to the range [0, 1] based on min and max values.\n",
        "\n",
        "        Args:\n",
        "            data (torch.Tensor): The input data tensor to be normalized.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The normalized data tensor.\n",
        "        \"\"\"\n",
        "        min_vals, _ = data.min(dim=0, keepdim=True)\n",
        "        max_vals, _ = data.max(dim=0, keepdim=True)\n",
        "        normalized_data = (data - min_vals) / (max_vals - min_vals)\n",
        "        return normalized_data\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Data:\n",
        "        \"\"\"\n",
        "        Get a graph data item for GNN processing.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the item.\n",
        "\n",
        "        Returns:\n",
        "            Data: A PyTorch Geometric Data object containing edge_index, x (node features), and y (target variable).\n",
        "        \"\"\"\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        if idx in self.cache:\n",
        "            return self.cache[idx]\n",
        "\n",
        "        row = self.data_frame.iloc[idx]\n",
        "        stl_path = os.path.join(self.root_dir, f\"{row['Design']}.stl\")\n",
        "        cd_value = row['Average Cd']\n",
        "\n",
        "        # Load the mesh from STL\n",
        "        try:\n",
        "            mesh = trimesh.load(stl_path, force='mesh')\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load STL file: {stl_path}. Error: {e}\")\n",
        "            raise\n",
        "\n",
        "        # Convert mesh to graph\n",
        "        edge_index = torch.tensor(np.array(mesh.edges).T, dtype=torch.long)\n",
        "        x = torch.tensor(mesh.vertices, dtype=torch.float)  # Using vertex positions as features\n",
        "\n",
        "        if self.normalize:\n",
        "            x = self.min_max_normalize(x)\n",
        "\n",
        "        y = torch.tensor([cd_value], dtype=torch.float)  # Target variable as tensor\n",
        "\n",
        "        # Create a graph data object\n",
        "        data = Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "        self.cache[idx] = data\n",
        "        return data\n",
        "\n",
        "    def visualize_mesh_with_node(self, idx: int) -> None:\n",
        "        \"\"\"\n",
        "        Visualizes the mesh of a given sample index with triangles in light grey and nodes highlighted as spheres.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sample to visualize.\n",
        "        \"\"\"\n",
        "        row = self.data_frame.iloc[idx]\n",
        "        design_id = row['Design']\n",
        "        geometry_path = os.path.join(self.root_dir, f\"{design_id}.stl\")\n",
        "\n",
        "        try:\n",
        "            mesh = trimesh.load(geometry_path, force='mesh')\n",
        "            pv_mesh = pv.wrap(mesh)\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load STL file: {geometry_path}. Error: {e}\")\n",
        "            raise\n",
        "\n",
        "        plotter = pv.Plotter()\n",
        "        sns_blue = sns.color_palette(\"colorblind\")[0]\n",
        "\n",
        "        # Add the mesh to the plotter with light grey color\n",
        "        plotter.add_mesh(pv_mesh, color='lightgrey', show_edges=True, edge_color='black')\n",
        "\n",
        "        # Highlight nodes as spheres\n",
        "        nodes = pv_mesh.points\n",
        "        plotter.add_points(nodes, color=sns_blue, point_size=5, render_points_as_spheres=True)  # Increase point_size as needed\n",
        "\n",
        "        plotter.add_axes()\n",
        "        camera_position = [(-11.073024242161921, -5.621499358347753, 5.862225824910342),\n",
        "                           (1.458462064391673, 0.002314306982062475, 0.6792134746589196),\n",
        "                           (0.34000174095454166, 0.10379556639001211, 0.9346792479485448)]\n",
        "\n",
        "        # Set the camera position\n",
        "        plotter.camera_position = camera_position\n",
        "        plotter.show()\n",
        "\n",
        "    def visualize_graph(self, idx: int) -> None:\n",
        "        \"\"\"\n",
        "        Visualizes the graph representation of the 3D mesh using PyVista.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sample to visualize.\n",
        "        \"\"\"\n",
        "        data = self[idx]  # Get the data object\n",
        "        mesh = pv.PolyData(data.x.numpy())  # Create a PyVista mesh from node features\n",
        "\n",
        "        # Create edges array suitable for PyVista\n",
        "        edges = data.edge_index.t().numpy()\n",
        "        lines = np.full((edges.shape[0], 3), 2, dtype=np.int_)\n",
        "        lines[:, 1:] = edges\n",
        "\n",
        "        mesh.lines = lines\n",
        "        mesh['scalars'] = np.random.rand(mesh.n_points)  # Random colors for nodes\n",
        "\n",
        "        plotter = pv.Plotter()\n",
        "        plotter.add_mesh(mesh, show_edges=True, line_width=1, color='white', point_size=8, render_points_as_spheres=True)\n",
        "        plotter.add_scalar_bar('Scalar Values', 'scalars')\n",
        "\n",
        "        # Optional: highlight edges for clarity\n",
        "        edge_points = mesh.points[edges.flatten()]\n",
        "        lines = pv.lines_from_points(edge_points)\n",
        "        plotter.add_mesh(lines, color='blue', line_width=2)\n",
        "\n",
        "        plotter.show()\n",
        "\n",
        "\n",
        "# # Example usage\n",
        "# if __name__ == '__main__':\n",
        "#     dataset = DrivAerNetDataset(root_dir='../DrivAerNetPlusPlus_combined_all',\n",
        "#                                 csv_file='../Combined_AeroCoefficients_DrivAerNet.csv',\n",
        "#                                 num_points=100000,\n",
        "#                                 pointcloud_exist=False  # Set to False if point clouds do not exist as .pt files\n",
        "#                                 )\n",
        "#\n",
        "#     dataset.visualize_mesh_with_node(10)  # Visualize the mesh with nodes of the 300th sample\n",
        "#\n",
        "#     dataset.visualize_point_cloud(10)  # Visualize the point cloud of the 300th sample\n",
        "#\n",
        "#     # Splitting data into train, validation, and test sets\n",
        "#     #train_indices, val_indices, test_indices = dataset.split_data()\n",
        "#     #logging.info(f\"Train size: {len(train_indices)}, Validation size: {len(val_indices)}, Test size: {len(test_indices)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRuXG5Io3ENr",
        "outputId": "a2d223f1-9024-406a-c14c-87ec3f7ed244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyvista\n",
            "  Downloading pyvista-0.44.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: matplotlib>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from pyvista) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pyvista) (1.24.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pyvista) (11.1.0)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from pyvista) (1.8.2)\n",
            "Requirement already satisfied: scooby>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from pyvista) (0.10.0)\n",
            "Collecting vtk<9.4.0 (from pyvista)\n",
            "  Downloading vtk-9.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyvista) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->pyvista) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch->pyvista) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.1->pyvista) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->pyvista) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->pyvista) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->pyvista) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->pyvista) (2025.1.31)\n",
            "Downloading pyvista-0.44.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vtk-9.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m92.1/92.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vtk, pyvista\n",
            "Successfully installed pyvista-0.44.2 vtk-9.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyvista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "GHNNx9rM1D_R",
        "outputId": "cd0a9919-b7f1-4958-d227-1b4f4e997c68"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import trimesh\n",
        "import pyvista as pv\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'exp_name': 'DragPrediction_DrivAerNet_PointNet_Showcase',\n",
        "    'cuda': True,\n",
        "    'seed': 42,\n",
        "    'num_points': 100000,\n",
        "    'dropout': 0.0,\n",
        "    'emb_dims': 1024,\n",
        "    'k': 40,\n",
        "    'channels': [6, 64, 128, 256, 512, 1024],\n",
        "    'linear_sizes': [128, 64, 32, 16],\n",
        "    'output_channels': 1,\n",
        "    'dataset_path': '/content/sample_data/DrivAerNet_ParametricData.csv',\n",
        "    'aero_coeff': '/Users/aswin/data/DrivAerNet/ParametricModels/DrivAerNet_ParametricData.csv',\n",
        "}\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() and config['cuda'] else \"cpu\")\n",
        "\n",
        "# Utility Functions\n",
        "def setup_seed(seed: int):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def initialize_model(config: dict) -> torch.nn.Module:\n",
        "    model = RegPointNet(args=config).to(device)\n",
        "    if config['cuda'] and torch.cuda.device_count() > 1:\n",
        "        model = torch.nn.DataParallel(model, device_ids=[0, 2, 3])\n",
        "    return model\n",
        "\n",
        "# Killer Feature 1: Real-Time Drag Prediction\n",
        "def predict_drag(model, geometry_path: str, num_points: int, dataset) -> float:\n",
        "    model.eval()\n",
        "    mesh = trimesh.load(geometry_path, force='mesh')\n",
        "    vertices = torch.tensor(mesh.vertices, dtype=torch.float32)\n",
        "    if vertices.size(0) != num_points:\n",
        "        vertices = dataset._sample_or_pad_vertices(vertices, num_points)\n",
        "    vertices = dataset.min_max_normalize(vertices).unsqueeze(0).permute(0, 2, 1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        start_time = time.time()\n",
        "        output = model(vertices).item()\n",
        "        inference_time = time.time() - start_time\n",
        "        print(f\"Predicted Cd: {output:.4f}, Inference Time: {inference_time:.4f}s\")\n",
        "    return output\n",
        "\n",
        "# Killer Feature 2: Drag Sensitivity Visualization\n",
        "def visualize_sensitivity(model, geometry_path: str, num_points: int, dataset):\n",
        "    model.eval()\n",
        "    mesh = trimesh.load(geometry_path, force='mesh')\n",
        "    vertices = torch.tensor(mesh.vertices, dtype=torch.float32, requires_grad=True)\n",
        "    if vertices.size(0) != num_points:\n",
        "        vertices = dataset._sample_or_pad_vertices(vertices, num_points)\n",
        "    vertices_normalized = dataset.min_max_normalize(vertices).unsqueeze(0).permute(0, 2, 1).to(device)\n",
        "\n",
        "    output = model(vertices_normalized)\n",
        "    output.backward()\n",
        "    sensitivity = vertices.grad.abs().sum(dim=1).cpu().numpy()\n",
        "\n",
        "    pv_mesh = pv.wrap(mesh)\n",
        "    pv_mesh.point_data['sensitivity'] = sensitivity\n",
        "    plotter = pv.Plotter()\n",
        "    plotter.add_mesh(pv_mesh, scalars='sensitivity', cmap='hot', show_edges=True)\n",
        "    plotter.add_scalar_bar(title='Drag Sensitivity')\n",
        "    plotter.show()\n",
        "\n",
        "# Killer Feature 3: Automated Design Optimization\n",
        "def optimize_geometry(model, geometry_path: str, num_points: int, dataset, steps: int = 100, lr: float = 0.01):\n",
        "    model.eval()\n",
        "    mesh = trimesh.load(geometry_path, force='mesh')\n",
        "    vertices = torch.tensor(mesh.vertices, dtype=torch.float32, requires_grad=True)\n",
        "    if vertices.size(0) != num_points:\n",
        "        vertices = dataset._sample_or_pad_vertices(vertices, num_points)\n",
        "    vertices_normalized = dataset.min_max_normalize(vertices).clone().detach().requires_grad_(True).to(device)\n",
        "    optimizer = optim.Adam([vertices_normalized], lr=lr)\n",
        "\n",
        "    for step in range(steps):\n",
        "        optimizer.zero_grad()\n",
        "        input_data = vertices_normalized.unsqueeze(0).permute(0, 2, 1)\n",
        "        cd_pred = model(input_data)\n",
        "        cd_pred.backward()\n",
        "        optimizer.step()\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Step {step}, Predicted Cd: {cd_pred.item():.4f}\")\n",
        "\n",
        "    optimized_vertices = vertices_normalized.detach().cpu().numpy()\n",
        "    return optimized_vertices\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Set random seed for reproducibility\n",
        "    setup_seed(config['seed'])\n",
        "\n",
        "    # Initialize the model\n",
        "    model = initialize_model(config)\n",
        "\n",
        "    # Load the pre-trained model checkpoint\n",
        "    best_model_path = os.path.join('models', f'{config[\"exp_name\"]}_best_model.pth')\n",
        "    if not os.path.exists(best_model_path):\n",
        "        raise FileNotFoundError(f\"Pre-trained model not found at {best_model_path}. Please provide a trained model checkpoint.\")\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "    print(f\"Loaded pre-trained model from {best_model_path}\")\n",
        "\n",
        "    # Initialize dataset for normalization utilities\n",
        "    dataset = DrivAerNetDataset(\n",
        "        root_dir=config['dataset_path'],\n",
        "        csv_file=config['aero_coeff'],\n",
        "        num_points=config['num_points'],\n",
        "        pointcloud_exist=True\n",
        "    )\n",
        "\n",
        "    # Example geometry path (replace with an actual mesh file, e.g., .stl or .obj)\n",
        "    sample_geometry = \"/content/sample_data/DrivAerNet_ParametricData.csv\"  # Replace with a valid mesh file path\n",
        "\n",
        "    # Killer Feature 1: Real-Time Drag Prediction\n",
        "    print(\"Killer Feature 1: Real-Time Drag Prediction\")\n",
        "    drag_coeff = predict_drag(model, sample_geometry, config['num_points'], dataset)\n",
        "\n",
        "    # Killer Feature 2: Drag Sensitivity Visualization\n",
        "    print(\"Killer Feature 2: Drag Sensitivity Visualization\")\n",
        "    visualize_sensitivity(model, sample_geometry, config['num_points'], dataset)\n",
        "\n",
        "    # Killer Feature 3: Automated Design Optimization\n",
        "    print(\"Killer Feature 3: Automated Design Optimization\")\n",
        "    optimized_vertices = optimize_geometry(model, sample_geometry, config['num_points'], dataset)\n",
        "    print(f\"Optimized geometry vertices shape: {optimized_vertices.shape}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
